__all__ = ["TravelPlannerAgent", "graph_executor"]

import json
from typing import Dict, Optional, TypedDict
from sse_starlette.sse import EventSourceResponse, ServerSentEvent
from langchain.memory import ConversationBufferMemory
from core.config import env

from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate, ChatPromptTemplate
from langchain.chains import ConversationChain
from langchain_openai import ChatOpenAI
from core.config import SESSION_MEMORIES
from langgraph.graph import StateGraph
from langchain.agents import AgentExecutor
from langgraph.prebuilt import tools_condition
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.prebuilt import create_react_agent


class TravelState(TypedDict):
    location: Optional[str]
    period: Optional[str]
    companion: Optional[str]
    style: Optional[str]
    completed: bool


class TravelPlannerAgent:
    """
    AgentServiceëŠ” í•˜ë‚˜ì˜ ëŒ€í™” ì„¸ì…˜ì„ ê´€ë¦¬í•˜ëŠ” ì‹¤ì§ˆì ì¸ Agent ë¶€ë¶„ì…ë‹ˆë‹¤.
    ê·¸ë ‡ê¸°ì— ì±„íŒ… ë‹¨ìœ„ë¡œ AgentServiceë¥¼ ìƒì„±í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        session_id: str = "test",
        location: Optional[str] = None,
        period: Optional[str] = None,
        companion: Optional[str] = None,
        style: Optional[str] = None,
    ):
        self.session_id = session_id
        self.graphState = TravelState(
            location=location,
            period=period,
            companion=companion,
            style=style,
            completed=False,
        )

    def get_weather(city: str) -> str:
        """Get weather for a given city."""
        return f"It's always sunny in {city}!"

    async def get_main_agent(self):
        agent = create_react_agent(
            f"{env.LLM_PROVIDER}:{env.LLM_MODEL}",
            tools=[self.get_weather],
            checkpointer=InMemorySaver(),
        )
        return agent

    def build_graph(self):
        graph = StateGraph()
        graph.add_node("planner", self.travel_planner_node)
        graph.add_node("attraction", self.tourist_attraction_node)
        graph.add_node("calendar", self.calendar_node)
        graph.set_entry_point("planner")
        graph.add_edge(
            "planner", "attraction", condition=lambda state: state["completed"]
        )
        graph.add_edge(
            "attraction", "calendar", condition=lambda state: state["completed"]
        )
        graph.add_edge(
            "calendar", "planner", condition=lambda state: not state["completed"]
        )
        return graph.compile()

    async def initialize_session_memory(self):
        SESSION_MEMORIES[self.session_id] = ConversationBufferMemory(
            memory_key="history", return_messages=True
        )

    async def initialize_session_memory(self):
        SESSION_MEMORIES[self.session_id] = ConversationBufferMemory(
            memory_key="history", return_messages=True
        )

    async def travel_planner_node(self, state: TravelState, message: str):
        """ì—¬í–‰ ì¼ì • ìˆ˜ë¦½ ë…¸ë“œ (ë¹„ë™ê¸°, LLM ë°œí™” í¬í•¨)"""
        memory = SESSION_MEMORIES.get(self.session_id)
        llm = ChatOpenAI(temperature=0, model="gpt-4", streaming=True)
        prompt = PromptTemplate(
            input_variables=["history", "input"],
            template="""
            ë‹¹ì‹ ì€ ì—¬í–‰ ì¼ì •ì„ ìˆ˜ë¦½í•˜ëŠ” AI í”Œë˜ë„ˆì…ë‹ˆë‹¤.

            {history}
            ì‚¬ìš©ì: {input}
            AI:""",
        )
        chain = ConversationChain(llm=llm, memory=memory, prompt=prompt, verbose=True)

        async def event_generator():
            async for chunk in chain.astream({"input": message}):
                if chunk.get("response"):
                    yield ServerSentEvent(
                        data=json.dumps(
                            {"message": chunk["response"], "terminated": False}
                        ),
                        event="message",
                    )
            yield ServerSentEvent(
                data=json.dumps({"message": "", "terminated": True}), event="end"
            )

        return EventSourceResponse(event_generator())

    async def tourist_attraction_node(self, state: TravelState):
        """ê´€ê´‘ëª…ì†Œ ê²€ìƒ‰ ë…¸ë“œ (ë¹„ë™ê¸° ì˜ˆì‹œ)"""
        attractions = f"[{state.location}] ì£¼ë³€ ê´€ê´‘ëª…ì†Œ 5ê³³ ì¶”ì²œ"
        yield ServerSentEvent(
            data=json.dumps({"message": attractions, "terminated": True}),
            event="message",
        )

    async def calendar_node(self, state: TravelState):
        """ìº˜ë¦°ë” ë“±ë¡ ë…¸ë“œ (ë¹„ë™ê¸° ì˜ˆì‹œ)"""
        calendar_result = f"ì¼ì •ì„ {state.period}ì— ìº˜ë¦°ë”ì— ë“±ë¡ ì™„ë£Œ!"
        yield ServerSentEvent(
            data=json.dumps({"message": calendar_result, "terminated": True}),
            event="message",
        )

    async def run(self):
        graph = StateGraph(self.graphState)

        graph.add_node("planner", self.travel_planner_node)
        graph.add_node("attraction", self.tourist_attraction_node)
        graph.add_node("calendar", self.calendar_node)

        graph.set_entry_point("planner")
        graph.add_edge("planner", "attraction", condition=lambda state: state.completed)
        graph.add_edge(
            "attraction", "calendar", condition=lambda state: state.completed
        )
        graph.add_edge(
            "calendar", "planner", condition=lambda state: not state.completed
        )

        executor = graph.compile()
        state = self.graphState

        # ì‚¬ìš©ì ì…ë ¥ ì‹œë®¬ë ˆì´ì…˜
        messages = ["ì„œìš¸", "7ì›” 20ì¼", "ê°€ì¡±", "íœ´ì–‘"]
        for msg in messages:
            output = await executor.astep(state, msg)  # ë¹„ë™ê¸° ìŠ¤í…
            print(output)

    async def event_generator_error(self, error_message: str):
        yield ServerSentEvent(
            data=json.dumps({"error": error_message, "terminated": True}), event="error"
        )

    async def get_agent_response(self, user_query: str):
        memory = SESSION_MEMORIES.get(self.session_id)
        if not memory:
            return EventSourceResponse(self.event_generator_error("Invalid session ID"))

        # ğŸ“œ í”„ë¡¬í”„íŠ¸
        template = """ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤.

    {history}
    Human: {input}
    AI:"""

        prompt = PromptTemplate(input_variables=["history", "input"], template=template)

        # ğŸ”— ì²´ì¸ ìƒì„±
        llm = ChatOpenAI(
            temperature=0, model="gpt-4", api_key=env.OPENAI_API_KEY, streaming=True
        )

        chain = ConversationChain(llm=llm, memory=memory, prompt=prompt, verbose=True)

        async def event_generator():
            try:
                async for chunk in chain.astream({"input": user_query}):
                    if chunk.get("response"):
                        yield ServerSentEvent(
                            data=json.dumps(
                                {"message": chunk["response"], "terminated": False}
                            ),
                            event="message",
                        )
                # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ
                yield ServerSentEvent(
                    data=json.dumps({"message": "", "terminated": True}), event="end"
                )
            except Exception as e:
                yield ServerSentEvent(
                    data=json.dumps({"error": str(e), "terminated": True}),
                    event="error",
                )

        return EventSourceResponse(event_generator())

    async def event_generator_error(error_message: str):
        yield ServerSentEvent(
            data=json.dumps({"error": error_message, "terminated": True}), event="error"
        )
